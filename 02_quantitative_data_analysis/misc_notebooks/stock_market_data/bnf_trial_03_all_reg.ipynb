{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,1:-2].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 :- Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_lr = lr.predict(xtest) ### The prediction which we will be comparing the final scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 :- Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "xtrain_pf = pf.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plr = LinearRegression()\n",
    "plr.fit(xtrain_pf,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_plr = plr.predict(pf.transform(xtest)) ### The prediction which we will be comparing the final scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 :- SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scx = StandardScaler()\n",
    "scy = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_scx = scx.fit_transform(xtrain)\n",
    "ytrain_scy = scy.fit_transform(ytrain.reshape(len(ytrain),1))\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(xtrain_scx,ytrain_scy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_svr = scy.inverse_transform(svr.predict(scx.transform(xtest))) ### The prediction which we will be comparing the final scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 :- Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_dtr = dtr.predict(xtest) ### The prediction which we will be comparing the final scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 :- Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_rfr = rfr.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the models for the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "mean squared error :- 0.3203964630084316\n",
      "r2 score :- -0.049262443149421964\n",
      "********************\n",
      "Polynomial Regression\n",
      "mean squared error :- 1.6288874469402854\n",
      "r2 score :- -4.334423501881825\n",
      "********************\n",
      "Linear Regression\n",
      "mean squared error :- 0.316988949205911\n",
      "r2 score :- -0.0381032180321208\n",
      "********************\n",
      "Linear Regression\n",
      "mean squared error :- 0.5880390622575344\n",
      "r2 score :- -0.925761905540756\n",
      "********************\n",
      "Linear Regression\n",
      "mean squared error :- 0.3492279980801978\n",
      "r2 score :- -0.1436824833867374\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "mser_lr = mean_squared_error(ytest, yp_lr)\n",
    "rer_lr = r2_score(ytest,yp_lr)\n",
    "print(\"Linear Regression\")\n",
    "print(f\"mean squared error :- {mser_lr}\")\n",
    "print(f\"r2 score :- {rer_lr}\")\n",
    "print(\"*\"*20)\n",
    "\n",
    "mser_plr = mean_squared_error(ytest, yp_plr)\n",
    "rer_plr = r2_score(ytest,yp_plr)\n",
    "print(\"Polynomial Regression\")\n",
    "print(f\"mean squared error :- {mser_plr}\")\n",
    "print(f\"r2 score :- {rer_plr}\")\n",
    "print(\"*\"*20)\n",
    "\n",
    "mser_svr = mean_squared_error(ytest, yp_svr)\n",
    "rer_svr = r2_score(ytest,yp_svr)\n",
    "print(\"Linear Regression\")\n",
    "print(f\"mean squared error :- {mser_svr}\")\n",
    "print(f\"r2 score :- {rer_svr}\")\n",
    "print(\"*\"*20)\n",
    "\n",
    "mser_dtr = mean_squared_error(ytest, yp_dtr)\n",
    "rer_dtr = r2_score(ytest,yp_dtr)\n",
    "print(\"Linear Regression\")\n",
    "print(f\"mean squared error :- {mser_dtr}\")\n",
    "print(f\"r2 score :- {rer_dtr}\")\n",
    "print(\"*\"*20)\n",
    "\n",
    "mser_rfr = mean_squared_error(ytest, yp_rfr)\n",
    "rer_rfr = r2_score(ytest,yp_rfr)\n",
    "print(\"Linear Regression\")\n",
    "print(f\"mean squared error :- {mser_rfr}\")\n",
    "print(f\"r2 score :- {rer_rfr}\")\n",
    "print(\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
