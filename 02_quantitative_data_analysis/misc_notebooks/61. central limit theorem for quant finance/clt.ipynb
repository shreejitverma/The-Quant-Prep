{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9129299d",
   "metadata": {},
   "source": [
    "###  Central Limit Theorem for Quant Finance\n",
    "\n",
    "##### ▶️ Related Quant Guild Videos:\n",
    "\n",
    "- [Time Series Analysis for Quant Finance](https://youtu.be/JwqjuUnR8OY)\n",
    "\n",
    "- [Quant Trader on Retail vs Institutional Trading](https://youtu.be/j1XAcdEHzbU)\n",
    "\n",
    "- [Quant on Trading and Investing](https://youtu.be/CKXp_sMwPuY)\n",
    "\n",
    "- [Why Poker Pros Make the Best Traders (It's NOT Luck)](https://youtu.be/wZChBKDFFeU)\n",
    "\n",
    "- [Quant vs. Discretionary Trading](https://youtu.be/3gblERSSHXI)\n",
    "\n",
    "- [Quant Busts 3 Trading Myths with Math](https://youtu.be/wJfIk3VnubE)\n",
    "\n",
    "###### ______________________________________________________________________________________________________________________________________\n",
    "\n",
    "##### [ Master your Quantitative Skills with Quant Guild](https://quantguild.com)\n",
    "\n",
    "##### [ Want to chat?  Meet with me 1:1](https://calendly.com/quantguild-support)\n",
    "\n",
    "##### [ Visit the Quant Guild Library for more Jupyter Notebooks](https://github.com/romanmichaelpaolucci/Quant-Guild-Library)\n",
    "\n",
    "##### [ Interactive Brokers for Algorithmic Trading](https://www.interactivebrokers.com/mkt/?src=quantguildY&url=%2Fen%2Fwhyib%2Foverview.php)\n",
    "\n",
    "##### [ Quant Guild Discord](discord.com/invite/MJ4FU2c6c3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* Overwrite the hard-coded white background for ipywidgets */\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    "/* Set widget foreground text and color to match the VS Code dark theme */\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde1bf4f",
   "metadata": {},
   "source": [
    "###  Sections\n",
    "\n",
    "#### 1.)  Random Variables and Statistics\n",
    "\n",
    "- Random Variables\n",
    "\n",
    "- Statistics and Distributions\n",
    "\n",
    "- Law of Large Numbers (LLN)\n",
    "\n",
    "- Application and Considerations\n",
    "\n",
    "#### 2.)  Normal Random Variables\n",
    "\n",
    "- Definition and Convergence\n",
    "\n",
    "- Likelihoods vs Probabilities\n",
    "\n",
    "- Statistics and Characteristics\n",
    "\n",
    "#### 3.)  Central Limit Theorem (CLT)\n",
    "\n",
    "- Rough Proof using the Characteristic Function\n",
    "\n",
    "- Example: Poisson Distribution\n",
    "\n",
    "- Application to Stock Returns and Trading\n",
    "\n",
    "#### 4.)  Closing Thoughts and Future Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae3ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0dce55",
   "metadata": {},
   "source": [
    "#### 1.)  Random Variables and Statistics\n",
    "\n",
    "##### Random Variables, Population and Empirical Distributions\n",
    "\n",
    "Random variables define a set of possible outcomes with accompanying probabilities or likelihoods\n",
    "\n",
    "They are fully specified by their\n",
    "\n",
    "- Probability mass or density function\n",
    "\n",
    "- Cumulative distribution function\n",
    "\n",
    "- Characteristic function\n",
    "\n",
    "There are **a lot** of different types of random variables (both discrete and continuous)\n",
    "\n",
    "We can model the total number of events over a specific time interval as a Poisson random variable\n",
    "\n",
    "Let $X \\sim Pois(\\lambda)$ be the number of trades executed on a particular instrument every 100ms\n",
    "\n",
    "- $\\lambda$ is the expected (average) number of trades over the specified time interval (100ms)\n",
    " \n",
    " The Poisson distribution with parameter $\\lambda$ has:\n",
    " \n",
    " $$\n",
    " \\text{PMF: } P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\quad\\quad \\text{CDF: } F(k) = \\sum_{n=0}^k \\frac{\\lambda^n e^{-\\lambda}}{n!} \\quad\\quad \\text{CF: }\\varphi(t) = \\exp\\left(\\lambda (e^{it} - 1)\\right)\n",
    " $$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# --- Setup ---\n",
    "lmbda = 4  # Poisson parameter (mean/events rate)\n",
    "poisson_support = np.arange(0, 13)\n",
    "pmf_poisson = poisson.pmf(poisson_support, lmbda)\n",
    "n_trials = 250\n",
    "np.random.seed(42)\n",
    "samples = np.random.poisson(lmbda, size=n_trials)\n",
    "\n",
    "# --- Helper: construct figure for a given step ---\n",
    "def make_poisson_empirical_convergence_fig(step):\n",
    "    drawn = samples[step]\n",
    "    counts = np.bincount(samples[:step+1], minlength=poisson_support[-1]+1)\n",
    "    empirical_pmf = counts / (step + 1)\n",
    "    # For display, align with support\n",
    "    empirical_display = empirical_pmf[:len(poisson_support)]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Poisson Mass Function\", \"Empirical Mass Function\"),\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: true PMF ---\n",
    "    bar_colors = ['#d400ff'] * len(poisson_support)  # neon purple\n",
    "    border_colors = ['rgba(0,0,0,0)'] * len(poisson_support)\n",
    "    border_widths = [0] * len(poisson_support)\n",
    "    if drawn < len(poisson_support):\n",
    "        bar_idx = drawn\n",
    "        border_colors[bar_idx] = '#FFD700'\n",
    "        border_widths[bar_idx] = 4\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=poisson_support,\n",
    "            y=pmf_poisson,\n",
    "            width=0.5,\n",
    "            marker=dict(color=bar_colors, line=dict(color=border_colors, width=border_widths)),\n",
    "            name=\"Poisson PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: empirical PMF over time ---\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=poisson_support,\n",
    "            y=empirical_display,\n",
    "            width=0.5,\n",
    "            marker=dict(color='#00ffff', opacity=0.8),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Overlay theoretical PMF on the right for comparison ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=poisson_support,\n",
    "            y=pmf_poisson,\n",
    "            mode='lines',\n",
    "            line=dict(color='#d400ff', width=3, dash='dash'),\n",
    "            name=\"Theoretical Poisson PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Legend-only traces ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(color='#d400ff', width=4),\n",
    "            name=\"Poisson PMF\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(color='#00ffff', width=4),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Axes ---\n",
    "    fig.update_xaxes(title_text=\"k\", row=1, col=1, range=[-0.5, poisson_support[-1]+0.5], tickvals=poisson_support)\n",
    "    fig.update_yaxes(title_text=\"P(X=k)\", row=1, col=1, range=[0, np.max(pmf_poisson)*1.15])\n",
    "    fig.update_xaxes(title_text=\"k\", row=1, col=2, range=[-0.5, poisson_support[-1]+0.5], tickvals=poisson_support)\n",
    "    fig.update_yaxes(title_text=\"Empirical P(X=k)\", row=1, col=2, range=[0, np.max(pmf_poisson)*1.15])\n",
    "\n",
    "    # --- Subtle gridlines ---\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_layout(\n",
    "        height=480,\n",
    "        width=960,\n",
    "        title_text=\"Poisson(λ=4) Distribution vs Empirical Distribution (25000ms)\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0.97, y=0.98,\n",
    "            xanchor='right', yanchor='top',\n",
    "            orientation='v',\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            borderwidth=0,\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "poisson_frames = [\n",
    "    go.Frame(data=make_poisson_empirical_convergence_fig(step).data, name=str(step))\n",
    "    for step in range(n_trials)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig = make_poisson_empirical_convergence_fig(0)\n",
    "fig.frames = poisson_frames\n",
    "\n",
    "# --- Play button ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.11,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 20, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30044c2c",
   "metadata": {},
   "source": [
    "**Remarks:**  We can **never** predict a value for $X$, but we can estimate the probabilities of observing specific values and compute statistics of interest.  It turns out, if we are correct *on average* we can use values like the mean to inform trading and generate trading profits (a classic market-making example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea0d22",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40434432",
   "metadata": {},
   "source": [
    "##### Statistics and Distributions\n",
    "\n",
    "Statistics are random variables themselves, they are a function of data\n",
    "\n",
    "Suppose trades ($X$) every 100ms followed a poisson distribution with an average of $4$ trades per interval\n",
    "\n",
    "$$X \\sim Pois(4)$$\n",
    "\n",
    "Similar to how we have a population and empirical distribution, we have population and empirical statistics\n",
    "\n",
    " $$\n",
    " \\text{Population Mean: }\\quad \n",
    " \\mathbb{E}[X] = \\sum_{k=0}^\\infty k \\cdot \\frac{\\lambda^k e^{-\\lambda}}{k!} = \\lambda \\quad\\quad \\text{Sample Mean: }\\quad \n",
    " \\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
    " $$\n",
    " \n",
    " where $x_1, ..., x_n$ are observed values.  \n",
    " \n",
    " We are attempting to approximate the true mean of the population distribution given data, *assuming it follows the given distribution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dba0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# --- Setup ---\n",
    "lmbda = 4\n",
    "poisson_support = np.arange(0, 13)\n",
    "pmf_poisson = poisson.pmf(poisson_support, lmbda)\n",
    "pmf_poisson /= pmf_poisson.sum()  # normalize\n",
    "n_samples_per_iter = 10\n",
    "n_iters = 10\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Simulation of 10 sets of 30 draws ---\n",
    "means = []\n",
    "empirical_pmfs = []\n",
    "for i in range(n_iters):\n",
    "    sample = np.random.choice(poisson_support, size=n_samples_per_iter, p=pmf_poisson)\n",
    "    means.append(np.mean(sample))\n",
    "    counts = np.bincount(sample, minlength=len(poisson_support))\n",
    "    empirical_pmfs.append(counts / n_samples_per_iter)\n",
    "\n",
    "# --- Figure generator for each frame ---\n",
    "def make_sampling_mean_fig(iteration):\n",
    "    emp_pmf = empirical_pmfs[iteration]\n",
    "    mean_so_far = means[:iteration + 1]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Empirical Mass Function\", \"Sample Means by Iteration\")\n",
    "    )\n",
    "\n",
    "    # Left: empirical PMF\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=poisson_support,\n",
    "            y=emp_pmf,\n",
    "            marker=dict(color='#00ffff', opacity=0.8),\n",
    "            name=\"Empirical PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=poisson_support,\n",
    "            y=pmf_poisson,\n",
    "            mode='lines',\n",
    "            line=dict(color='#d400ff', width=3, dash='dash'),\n",
    "            name=\"True Poisson PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Right: sample means so far\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(range(1, len(mean_so_far)+1)),\n",
    "            y=mean_so_far,\n",
    "            marker=dict(color='#ff6fff', opacity=0.8),\n",
    "            name=\"Sample Means\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # True mean line\n",
    "    fig.add_hline(y=lmbda, line=dict(color='red', dash='dash'), row=1, col=2)\n",
    "\n",
    "    # Axes\n",
    "    fig.update_xaxes(title_text=\"k\", row=1, col=1, range=[-0.5, 12.5])\n",
    "    fig.update_yaxes(title_text=\"P(X=k)\", row=1, col=1, range=[0, max(pmf_poisson)*1.2])\n",
    "    fig.update_xaxes(title_text=\"Iteration\", row=1, col=2, range=[0.5, n_iters + 0.5])\n",
    "    fig.update_yaxes(title_text=\"Sample Mean\", row=1, col=2, range=[0, max(means)*1.2])\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        height=480, width=960,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        title_text=f\"Iteration {iteration+1}: Sample Mean = {mean_so_far[-1]:.2f}\",\n",
    "        title_x=0.5,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "frames = []\n",
    "for i in range(n_iters):\n",
    "    f = make_sampling_mean_fig(i)\n",
    "    frames.append(go.Frame(\n",
    "        data=f.data,\n",
    "        name=str(i),\n",
    "        layout=go.Layout(\n",
    "            title_text=f\"Iteration {i+1}: Sample Mean = {means[i]:.2f}\"\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig = make_sampling_mean_fig(0)\n",
    "fig.frames = frames\n",
    "\n",
    "# --- Animation controls ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.12,\n",
    "        'xanchor': 'center',\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 800, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 400, 'easing': 'cubic-in-out'}\n",
    "            }]\n",
    "        }]\n",
    "    }],\n",
    "    # subtle easing and transition effect\n",
    "    transition={'duration': 500, 'easing': 'cubic-in-out'}\n",
    ")\n",
    "\n",
    "# --- Bar entrance animation tweak ---\n",
    "for trace in fig.data:\n",
    "    if isinstance(trace, go.Bar):\n",
    "        trace.marker.opacity = 0.8\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f67e9",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e11eb",
   "metadata": {},
   "source": [
    "##### Law of Large Numbers (LLN)\n",
    "\n",
    "When drawing from the *same population distribution*, empirical statistics and distributions are gaurenteed to converge\n",
    "\n",
    "This is given by the Law of Large Numbers (LLN)\n",
    "\n",
    " $$\n",
    " \\frac{1}{n}\\sum_{i=1}^n h(X_i) \\longrightarrow \\mathbb{E}[h(X)] \\qquad \\text{and} \\qquad \\frac{1}{n}\\sum_{i=1}^n \\mathbf{1}_{\\{X_i \\leq x\\}} \\longrightarrow P(X \\leq x)\n",
    " $$\n",
    "The first equation expresses sample statistics convergence, the second shows distribution convergence by a series of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047cdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Parameters\n",
    "lmbda = 4\n",
    "poisson_support = np.arange(0, 13)\n",
    "pmf_poisson = poisson.pmf(poisson_support, lmbda)\n",
    "pmf_poisson = pmf_poisson / pmf_poisson.sum()\n",
    "n_trials = 300\n",
    "np.random.seed(3)\n",
    "\n",
    "samples = np.random.choice(poisson_support, size=n_trials, p=pmf_poisson)\n",
    "cumulative_means = np.cumsum(samples) / np.arange(1, n_trials + 1)\n",
    "\n",
    "def make_cumulative_mean_fig(step):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Empirical Mass Function\", \"Cumulative Sample Mean\")\n",
    "    )\n",
    "\n",
    "    # --- Left: Empirical PMF ---\n",
    "    counts = np.bincount(samples[:step + 1], minlength=len(poisson_support))\n",
    "    empirical_pmf = counts / (step + 1)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=poisson_support,\n",
    "            y=empirical_pmf,\n",
    "            marker=dict(color='#00ffff', opacity=0.7),\n",
    "            name=\"Empirical PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=poisson_support,\n",
    "            y=pmf_poisson,\n",
    "            mode='lines',\n",
    "            line=dict(color='#d400ff', width=3, dash='dash'),\n",
    "            name=\"True Poisson PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right: Cumulative Mean ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(1, step + 2),\n",
    "            y=cumulative_means[:step + 1],\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='#00ffff', width=3),\n",
    "            marker=dict(size=6, color='#00ffff'),\n",
    "            name=\"Cumulative Mean\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # True mean line\n",
    "    fig.add_hline(y=lmbda, line=dict(color='#d400ff', dash='dash'), row=1, col=2)\n",
    "\n",
    "    # --- Axes ---\n",
    "    fig.update_xaxes(title_text=\"k\", row=1, col=1, range=[-0.5, 12.5])\n",
    "    fig.update_yaxes(title_text=\"P(X=k)\", row=1, col=1, range=[0, max(pmf_poisson) * 1.2])\n",
    "\n",
    "    # Right chart: fixed y-range, but expanding x-range smoothly\n",
    "    fig.update_xaxes(title_text=\"Number of Draws\", row=1, col=2, range=[0, n_trials])\n",
    "    fig.update_yaxes(title_text=\"Sample Mean\", row=1, col=2, range=[3, 5])\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=500, width=950,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        title_text=f\"Draws: {step+1}, Cumulative Mean = {cumulative_means[step]:.2f}\",\n",
    "        title_x=0.5,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# --- Build frames ---\n",
    "frames = []\n",
    "for step in range(n_trials):\n",
    "    f = make_cumulative_mean_fig(step)\n",
    "    # xlim expands gradually to the right with each step\n",
    "    frames.append(go.Frame(\n",
    "        data=f.data,\n",
    "        name=str(step),\n",
    "        layout=go.Layout(\n",
    "            title_text=f\"Draws: {step+1}, Cumulative Mean = {cumulative_means[step]:.2f}\",\n",
    "            xaxis2=dict(range=[0, max(step + 5, 20)]),  # monotonically increasing xlim\n",
    "            yaxis2=dict(range=[3, 5]),\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "# --- Initialize & animate ---\n",
    "fig = make_cumulative_mean_fig(0)\n",
    "fig.frames = frames\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.12,\n",
    "        'xanchor': 'center',\n",
    "        'showactive': False,\n",
    "        'buttons': [dict(\n",
    "            label='Play',\n",
    "            method='animate',\n",
    "            args=[None, {\n",
    "                'frame': {'duration': 10, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 40, 'easing': 'cubic-in-out'}\n",
    "            }]\n",
    "        )]\n",
    "    }],\n",
    "    transition={'duration': 40, 'easing': 'cubic-in-out'}\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf1b51",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31783420",
   "metadata": {},
   "source": [
    "##### Applications and Considerations\n",
    "\n",
    "Above we **assumed** trades every 100ms for a particular instrument followed a Poisson distribution ($X \\sim Pois(4)$)\n",
    "\n",
    "Suppose we wanted to model the distribution of trades every 100ms to look for a tradable statistically abnormal deviation \n",
    "\n",
    "We can't observe the data generating distribution, otherwise we wouldn't need a model\n",
    "\n",
    "The best we can do is make assumptions and build a model (quite literally our job as quants)\n",
    "\n",
    "#### Example: Calibrated and Out of Sample (OOS) Trades Distribution 100ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c44345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# --- Setup ---\n",
    "lmbda = 4  # Poisson parameter (mean/events rate)\n",
    "poisson_support = np.arange(0, 13)\n",
    "pmf_poisson = poisson.pmf(poisson_support, lmbda)\n",
    "n_trials = 100\n",
    "np.random.seed(2)\n",
    "samples = np.random.poisson(lmbda, size=n_trials)\n",
    "\n",
    "# --- Helper: construct figure for a given step ---\n",
    "def make_poisson_empirical_convergence_fig(step):\n",
    "    drawn = samples[step]\n",
    "    counts = np.bincount(samples[:step+1], minlength=poisson_support[-1]+1)\n",
    "    empirical_pmf = counts / (step + 1)\n",
    "    # For display, align with support\n",
    "    empirical_display = empirical_pmf[:len(poisson_support)]\n",
    "\n",
    "    # --- SHIFT empirical chart to show lack of convergence (artificially offset)\n",
    "    shift_offset = -2  # <--- shifting right by 2 units\n",
    "\n",
    "    # Population mean (theoretical)\n",
    "    population_mean = lmbda\n",
    "    # Empirical mean from observed data\n",
    "    realized_mean = np.mean(samples[:step+1])\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Calibrated Poisson PMF\", \"OOS Empirical PMF\"),\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: true PMF ---\n",
    "    bar_colors = ['#d400ff'] * len(poisson_support)\n",
    "    border_colors = ['rgba(0,0,0,0)'] * len(poisson_support)\n",
    "    border_widths = [0] * len(poisson_support)\n",
    "    if drawn < len(poisson_support):\n",
    "        bar_idx = drawn\n",
    "        border_colors[bar_idx] = '#FFD700'\n",
    "        border_widths[bar_idx] = 4\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=poisson_support,\n",
    "            y=pmf_poisson,\n",
    "            width=0.5,\n",
    "            marker=dict(color=bar_colors, line=dict(color=border_colors, width=border_widths)),\n",
    "            name=\"Poisson PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: population mean vertical line only ---\n",
    "    fig.add_vline(\n",
    "        x=population_mean,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"#FFD700\",\n",
    "        line_width=3,\n",
    "        row=1, col=1,\n",
    "        annotation_text=\"Population Mean\",\n",
    "        annotation_position=\"top right\",\n",
    "        annotation_font=dict(color=\"#FFD700\", size=13),\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: empirical PMF over time (SHIFTED) ---\n",
    "    shifted_support = poisson_support + shift_offset\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=shifted_support,\n",
    "            y=empirical_display,\n",
    "            width=0.5,\n",
    "            marker=dict(color='#00ffff', opacity=0.8),\n",
    "            name=\"Empirical Distribution (Shifted)\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Overlay theoretical PMF on the right for comparison (NOT shifted) ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=poisson_support,\n",
    "            y=pmf_poisson,\n",
    "            mode='lines',\n",
    "            line=dict(color='#d400ff', width=3, dash='dash'),\n",
    "            name=\"Theoretical Poisson PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: Empirical mean (dynamic vertical line, SHIFTED) ---\n",
    "    fig.add_vline(\n",
    "        x=realized_mean + shift_offset,\n",
    "        line_dash=\"dot\",\n",
    "        line_color=\"red\",\n",
    "        line_width=3,\n",
    "        row=1, col=2,\n",
    "        annotation_text=\"Empirical Mean\",\n",
    "        annotation_position=\"top left\",\n",
    "        annotation_font=dict(color=\"red\", size=13),\n",
    "    )\n",
    "\n",
    "    # --- Axes ---\n",
    "    fig.update_xaxes(title_text=\"k\", row=1, col=1, range=[-0.5, poisson_support[-1]+0.5], tickvals=poisson_support)\n",
    "    fig.update_yaxes(title_text=\"P(X=k)\", row=1, col=1, range=[0, np.max(pmf_poisson)*1.15])\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"k\",\n",
    "        row=1, col=2,\n",
    "        range=[-0.5, poisson_support[-1]+0.5 + shift_offset],\n",
    "        tickvals=np.concatenate((poisson_support, shifted_support)),\n",
    "        showgrid=True, gridcolor='rgba(128,128,128,0.3)'\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"Empirical P(X=k)\", row=1, col=2, range=[0, np.max(pmf_poisson)*1.15], showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "    # --- Subtle gridlines for left plot still ---\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)', row=1, col=1)\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)', row=1, col=1)\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_layout(\n",
    "        height=480,\n",
    "        width=960,\n",
    "        title_text=\"Poisson(λ=4) Distribution vs Empirical Distribution (SHIFTED, 10000ms)\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=False,\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "poisson_frames = [\n",
    "    go.Frame(data=make_poisson_empirical_convergence_fig(step).data, layout=make_poisson_empirical_convergence_fig(step).layout, name=str(step))\n",
    "    for step in range(n_trials)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig = make_poisson_empirical_convergence_fig(0)\n",
    "fig.frames = poisson_frames\n",
    "\n",
    "# --- Play button ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.11,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 20, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b196dba",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffd41a",
   "metadata": {},
   "source": [
    "#####  Key Questions for Evaluating Model Efficacy\n",
    "\n",
    "In reality, events are uncertain, not random variables - but we use these structures to model such outcomes (like # of trades in 100ms)\n",
    "\n",
    "- Is a Poisson distribution and accompanying assumptions reasonable to model trades every 100ms?\n",
    "- Is the distribution relatively stable or is there severe time variance?\n",
    "- Should it persist, is there a reasonable way to model the lack of stability and time variance?\n",
    "\n",
    "In any case, statistics (a function of our population or empirical distribution) are necessary for generating trading P/L\n",
    "\n",
    "This leads us to a big question (even after considering all of the above)\n",
    "\n",
    "**Is there a way to determine if the statistics we observe deviate significantly from a population statistic?** \n",
    "\n",
    "More specifically,\n",
    "\n",
    "**If statistics themselves are random variables, what distribution do they follow?**\n",
    "\n",
    "First, we must understand normal (Gaussian) random variables. . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98964f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10672232",
   "metadata": {},
   "source": [
    "#### 2.)  Normal Random Variables\n",
    "\n",
    "Normal (Gaussian) random variables are continuous and are again fully defined by. . .\n",
    "\n",
    "$$\\text{PDF: }f_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) \\quad\\quad \n",
    " \\text{CDF:} \\quad F_X(x) = \\int_{-\\infty}^x f_X(t) dt \\quad\\quad \\text{CF: }\\varphi_X(t) = \\exp\\left(i\\mu t - \\frac{1}{2}\\sigma^2 t^2\\right)$$\n",
    "\n",
    " $$\\text{CF: }\\varphi_X(t) = \\exp\\left( - \\frac{1}{2}t^2\\right)$$\n",
    "\n",
    "Convergence in both statistics and distribution is also gaurenteed by the Law of Large Numbers (LLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfaa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Normal Distribution Parameters ---\n",
    "mu = 0     # mean\n",
    "sigma = 1  # standard deviation\n",
    "\n",
    "# x support for standard normal\n",
    "x_support = np.linspace(mu - 4*sigma, mu + 4*sigma, 500)\n",
    "pdf_norm = norm.pdf(x_support, mu, sigma)\n",
    "\n",
    "# Set up initial sample size\n",
    "np.random.seed(0)\n",
    "n_samples = 300\n",
    "samples_normal = np.random.normal(mu, sigma, size=n_samples)\n",
    "\n",
    "def make_normal_empirical_convergence_fig(step):\n",
    "    drawn = samples_normal[step]\n",
    "    current_samples = samples_normal[:step+1]\n",
    "    \n",
    "    # Empirical histogram (normalize for PDF shape)\n",
    "    counts, bin_edges = np.histogram(current_samples, bins=16, range=(x_support[0], x_support[-1]), density=True)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\n",
    "            \"Standard Normal Distribution PDF\",\n",
    "            \"Normalized Empirical Histogram\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: true normal PDF with marker and vertical line ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_support,\n",
    "            y=pdf_norm,\n",
    "            mode='lines',\n",
    "            line=dict(color='#B026FF', width=3),\n",
    "            name=\"Standard Normal PDF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Mark the drawn value (left)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[drawn],\n",
    "            y=[norm.pdf(drawn, mu, sigma)],\n",
    "            mode='markers',\n",
    "            marker=dict(color='#FFD700', size=14, line=dict(color='black', width=2)),\n",
    "            name=\"Latest Sample\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add vertical yellow line at marker (left)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[drawn, drawn],\n",
    "            y=[0, norm.pdf(drawn, mu, sigma)],\n",
    "            mode='lines',\n",
    "            line=dict(color='#FFD700', width=3, dash='dot'),\n",
    "            showlegend=False,\n",
    "            hoverinfo='skip'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: empirical histogram & theoretical curve ---\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=bin_centers,\n",
    "            y=counts,\n",
    "            width=(bin_edges[1] - bin_edges[0]) * 0.98,\n",
    "            marker=dict(color='#00ffff', opacity=0.7),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Overlay the standard normal PDF (right)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_support,\n",
    "            y=pdf_norm,\n",
    "            mode='lines',\n",
    "            line=dict(color='#B026FF', width=3, dash='dash'),\n",
    "            name=\"Standard Normal PDF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Note: legend is removed, so don't add legend-only traces\n",
    "\n",
    "    # --- Axes ---\n",
    "    fig.update_xaxes(title_text=\"x\", row=1, col=1, range=[x_support[0], x_support[-1]])\n",
    "    fig.update_yaxes(title_text=\"Density\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"x\", row=1, col=2, range=[x_support[0], x_support[-1]])\n",
    "    # Configure right y-axis range to be 0 to .45\n",
    "    fig.update_yaxes(title_text=\"Empirical Density\", row=1, col=2, range=[0, 0.45])\n",
    "\n",
    "    # --- Gridlines ---\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_layout(\n",
    "        height=480,\n",
    "        width=960,\n",
    "        title_text=\"Standard Normal Distribution vs Empirical Distribution\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=False,  # Remove legend\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames for normal empirical convergence ---\n",
    "normal_frames = [\n",
    "    go.Frame(data=make_normal_empirical_convergence_fig(step).data, name=str(step))\n",
    "    for step in range(n_samples)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig_norm = make_normal_empirical_convergence_fig(0)\n",
    "fig_norm.frames = normal_frames\n",
    "\n",
    "# --- Play button ---\n",
    "fig_norm.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.11,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 20, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig_norm.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19933d",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e177d5",
   "metadata": {},
   "source": [
    "##### Likelihoods vs Probabilities\n",
    "\n",
    "Unlike discrete random variables, probabilities can only be recovered by integrating the density function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee945a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Normal Distribution Parameters ---\n",
    "mu, sigma = 0, 1\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 500)\n",
    "pdf = norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Initial slider points\n",
    "k1_initial, k2_initial = 0.5, 1.0\n",
    "idx_k1, idx_k2 = np.argmin(np.abs(x - k1_initial)), np.argmin(np.abs(x - k2_initial))\n",
    "k1_val, k2_val = x[idx_k1], x[idx_k2]\n",
    "\n",
    "y_max_pdf = np.max(pdf)*1.05\n",
    "\n",
    "# --- Figure Setup ---\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[f'Normal PDF (μ={mu}, σ={sigma})',\n",
    "                    f'PDF with Shaded Area (P(X≤k_2))']\n",
    ")\n",
    "\n",
    "# PDF line (left) - use neon purple\n",
    "fig.add_trace(go.Scatter(x=x, y=pdf, mode='lines',\n",
    "                         line=dict(color='#B026FF', width=3),  # neon purple\n",
    "                         name='PDF', hovertemplate='x=%{x:.2f}<br>PDF=%{y:.4f}<extra></extra>'),\n",
    "              row=1, col=1)\n",
    "\n",
    "# PDF line (right)\n",
    "fig.add_trace(go.Scatter(x=x, y=pdf, mode='lines',\n",
    "                         line=dict(color='#00ffff', width=3),\n",
    "                         name='PDF', hovertemplate='x=%{x:.2f}<br>PDF=%{y:.4f}<extra></extra>'),\n",
    "              row=1, col=2)\n",
    "\n",
    "# Shaded fill area under PDF (right)\n",
    "x_fill_initial = x[:idx_k2 + 1]\n",
    "pdf_fill_initial = pdf[:idx_k2 + 1]\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([x_fill_initial, x_fill_initial[::-1]]),\n",
    "    y=np.concatenate([pdf_fill_initial, np.zeros_like(pdf_fill_initial)]),\n",
    "    fill='toself', mode='none',\n",
    "    fillcolor='rgba(0,255,255,0.3)', name='P(X≤k2)', showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Compute P(X ≤ k2) for initial fill\n",
    "prob_k2 = norm.cdf(k2_val, mu, sigma)\n",
    "initial_title = (\n",
    "    f'Normal Distribution (μ={mu}, σ={sigma})'\n",
    "    f'<br>PDF Height at x={k1_val:.2f} is {pdf[idx_k1]:.4f}'\n",
    "    f' | P(X≤{k2_val:.2f}) = {prob_k2:.4f}'\n",
    ")\n",
    "\n",
    "INITIAL_SHAPES = [\n",
    "    dict(type='line', xref='x1', yref='y1', x0=k1_val, x1=k1_val, y0=0, y1=y_max_pdf,\n",
    "         line=dict(color='red', width=3, dash='dot')),\n",
    "    dict(type='line', xref='x2', yref='y2', x0=k2_val, x1=k2_val, y0=0, y1=y_max_pdf,\n",
    "         line=dict(color='yellow', width=3, dash='dot')),\n",
    "]\n",
    "\n",
    "# --- Sliders ---\n",
    "slider_k1_steps = []\n",
    "for i, k in enumerate(x):\n",
    "    pdf_k = pdf[i]\n",
    "    prob_current = norm.cdf(k2_val, mu, sigma)\n",
    "    step = dict(\n",
    "        method=\"relayout\",\n",
    "        label=\"\",\n",
    "        args=[{\n",
    "            \"title.text\": (\n",
    "                f'Normal Distribution (μ={mu}, σ={sigma})'\n",
    "                f'<br>PDF Height at x={k:.2f} is {pdf_k:.4f}'\n",
    "                f' | P(X≤{k2_val:.2f}) = {prob_current:.4f}'\n",
    "            ),\n",
    "            \"shapes[0].x0\": k,\n",
    "            \"shapes[0].x1\": k\n",
    "        }],\n",
    "        execute=True\n",
    "    )\n",
    "    slider_k1_steps.append(step)\n",
    "\n",
    "slider_k2_steps = []\n",
    "for i, k in enumerate(x):\n",
    "    x_fill = x[:i + 1]\n",
    "    pdf_fill = pdf[:i + 1]\n",
    "    prob_k = norm.cdf(k, mu, sigma)\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        label=\"\",\n",
    "        args=[\n",
    "            {\n",
    "                \"x\": [x, x, np.concatenate([x_fill, x_fill[::-1]])],\n",
    "                \"y\": [pdf, pdf, np.concatenate([pdf_fill, np.zeros_like(pdf_fill)])]\n",
    "            },\n",
    "            {\n",
    "                \"title.text\": (\n",
    "                    f'Normal Distribution (μ={mu}, σ={sigma})'\n",
    "                    f'<br>PDF Height at x={k1_val:.2f} is {pdf[idx_k1]:.4f}'\n",
    "                    f' | P(X≤{k:.2f}) = {prob_k:.4f}'\n",
    "                ),\n",
    "                \"shapes[1].x0\": k,\n",
    "                \"shapes[1].x1\": k\n",
    "            }\n",
    "        ],\n",
    "        execute=True\n",
    "    )\n",
    "    slider_k2_steps.append(step)\n",
    "\n",
    "# --- Layout ---\n",
    "# Move sliders further to the left and right so they clearly sit under their respective plots\n",
    "fig.update_layout(\n",
    "    height=550,\n",
    "    title={'text': initial_title, 'y': 0.97, 'x': 0.5, 'xanchor': 'center'},\n",
    "    font=dict(color='white'),\n",
    "    showlegend=False,\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    shapes=INITIAL_SHAPES,\n",
    "    sliders=[\n",
    "        dict(\n",
    "            steps=slider_k1_steps,\n",
    "            active=idx_k1,\n",
    "            pad={\"t\": 50, \"b\": 0},\n",
    "            yanchor='top', y=-0.10,\n",
    "            x=0.08, len=0.30   # move left slider further left under left plot\n",
    "        ),\n",
    "        dict(\n",
    "            steps=slider_k2_steps,\n",
    "            active=idx_k2,\n",
    "            pad={\"t\": 50, \"b\": 0},\n",
    "            yanchor='top', y=-0.10,\n",
    "            x=0.65, len=0.30   # move right slider further right under right plot\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Axes\n",
    "fig.update_xaxes(title_text='x', range=[mu - 4*sigma, mu + 4*sigma],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.2)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='f(x) (PDF)', range=[0, y_max_pdf],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.2)', row=1, col=1)\n",
    "fig.update_xaxes(range=[mu - 4*sigma, mu + 4*sigma],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.2)', row=1, col=2)\n",
    "fig.update_yaxes(range=[0, y_max_pdf],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.2)', row=1, col=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf964f2",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88c4c4",
   "metadata": {},
   "source": [
    "##### Statistics and Characteristics\n",
    "\n",
    "Normal distributions are defined in terms of a mean and variance\n",
    "\n",
    "$$X \\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "Regardless of the shape of the normal distribution, all of the properties above that we saw for a standard normal ($N(0, 1)$) hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Normal distributions: mean, sigma\n",
    "norm_params = [\n",
    "    (0, 1),    # Standard Normal\n",
    "    (2, 0.8),  # Shifted mean, smaller sigma\n",
    "    (-1, 1.5), # Lower mean, wider sigma\n",
    "]\n",
    "\n",
    "n_normals = len(norm_params)\n",
    "colors = ['#B026FF', '#FF8F00', '#00D4A1']  # purple, orange, greenish\n",
    "\n",
    "x = np.linspace(-5, 5, 500)\n",
    "\n",
    "pdfs = []\n",
    "for mu, sigma in norm_params:\n",
    "    pdfs.append(norm.pdf(x, mu, sigma))\n",
    "\n",
    "# We'll allow a slider to select which normal is current to \"integrate\"\n",
    "slider_steps = []\n",
    "shaded_colors = ['rgba(176,38,255,0.18)','rgba(255,143,0,0.18)','rgba(0,212,161,0.18)']\n",
    "\n",
    "# Set initial shaded area up to some value k2\n",
    "k2_init = 1.0\n",
    "k2_idx = np.argmin(np.abs(x - k2_init))\n",
    "\n",
    "x_fill_init = x[:k2_idx+1]\n",
    "\n",
    "# Setup Subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\n",
    "        'Normal PDFs: Various Mean & Variance',\n",
    "        'Integrating PDF up to k2 (Area = Probability)',  # Removed LaTeX\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Left: show all PDFs together, with a legend and distinct colors\n",
    "for i, (mu, sigma) in enumerate(norm_params):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=pdfs[i],\n",
    "            mode='lines',\n",
    "            line=dict(color=colors[i], width=3),\n",
    "            name=f\"N({mu},{sigma}²)\",  # No LaTeX\n",
    "            legendgroup=f\"group{i+1}\",\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Match grid lines to right subplot\n",
    "fig.update_xaxes(title_text='x', range=[-4.5, 4.5], showgrid=True, gridcolor='rgba(128,128,128,0.19)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='f(x) (PDF)', showgrid=True, gridcolor='rgba(128,128,128,0.19)', row=1, col=1)\n",
    "\n",
    "# On the right: show one PDF at a time, with the integrated region under the curve up to k2\n",
    "for i, (mu, sigma) in enumerate(norm_params):\n",
    "    y_pdf = pdfs[i]\n",
    "    x_fill = x[:k2_idx+1]\n",
    "    y_fill = y_pdf[:k2_idx+1]\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=y_pdf,\n",
    "            mode='lines',\n",
    "            line=dict(color=colors[i], width=3),\n",
    "            name=f\"N({mu},{sigma}²) (Active)\",  # No LaTeX\n",
    "            legendgroup=f\"group{i+1}\",\n",
    "            showlegend=False,\n",
    "            visible=(i == 0),\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    # Fill under curve\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.concatenate([x_fill, x_fill[::-1]]),\n",
    "            y=np.concatenate([y_fill, np.zeros_like(y_fill)]),\n",
    "            fill='toself', mode='none',\n",
    "            fillcolor=shaded_colors[i],\n",
    "            name=\"P(X ≤ k2)\",  # No LaTeX\n",
    "            showlegend=False,\n",
    "            visible=(i == 0),\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Compute the probability for each normal for initial k2\n",
    "prob_k2_vals = [norm.cdf(k2_init, p[0], p[1]) for p in norm_params]\n",
    "\n",
    "for i, (mu, sigma) in enumerate(norm_params):\n",
    "    # Toggle only the selected normal's PDF and fill in the right panel\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        label=f\"mu={mu}, sigma={sigma}\",  # No LaTeX\n",
    "        args=[\n",
    "            {\n",
    "                \"visible\": (\n",
    "                    ([True]*n_normals) +\n",
    "                    sum(([j==i, j==i] for j in range(n_normals)), [])\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"title.text\": (\n",
    "                    f\"<b>Normal PDFs (left): Various Mean & Variance</b>\"\n",
    "                    f\"<br><b>Right:</b> N({mu},{sigma}²) | \"  # No LaTeX\n",
    "                    f\"P(X ≤ {k2_init:.2f}) = {prob_k2_vals[i]:.4f}\"\n",
    "                )\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    slider_steps.append(step)\n",
    "\n",
    "# Construct slider to toggle between normals\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    title={'text': (\n",
    "        f\"<b>Normal PDFs (left): Various Mean & Variance</b>\"\n",
    "        f\"<br><b>Right:</b> N({norm_params[0][0]},{norm_params[0][1]}²) | \"\n",
    "        f\"P(X ≤ {k2_init:.2f}) = {prob_k2_vals[0]:.4f}\"\n",
    "    ), 'y':0.97, 'x':0.5, 'xanchor':'center'},\n",
    "    font=dict(color='white'),\n",
    "    showlegend=True,\n",
    "    legend=dict(font=dict(color='white'), bgcolor='rgba(0,0,0,0)', y=0.96, x=0.04),\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    sliders=[\n",
    "        dict(\n",
    "            steps=slider_steps,\n",
    "            active=0,\n",
    "            pad={\"t\": 45, \"b\": 0},\n",
    "            yanchor='top', y=-0.10,\n",
    "            x=0.56, len=0.40,\n",
    "            currentvalue=dict(\n",
    "                visible=True,\n",
    "                prefix=\"Distribution: \"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text='x', range=[-4.5, 4.5], showgrid=True, gridcolor='rgba(128,128,128,0.19)', row=1, col=2)\n",
    "fig.update_yaxes(title_text='f(x) (PDF)', showgrid=True, gridcolor='rgba(128,128,128,0.19)', row=1, col=2)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46ca12",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c8156",
   "metadata": {},
   "source": [
    "#####  Why do we care about the normal (Gaussian) distribution?\n",
    "\n",
    "#####  This is our bridge between probability and statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cf3d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb58fb0",
   "metadata": {},
   "source": [
    "#### 3.)  Central Limit Theorem (CLT)\n",
    "\n",
    "Amazingly, even if we don't know the population distribution, the CLT gaurentees the empirical (sample) mean is normally distributed\n",
    "\n",
    "#####  **Rough Proof using the Characteristic Function**\n",
    "\n",
    "We first look at the equation for the standardized sample mean\n",
    "\n",
    "$$Z_n = \\frac{\\sum_{i=1}^{n} X_i - n\\mu}{\\sigma\\sqrt{n}}$$\n",
    "\n",
    "Applying the characteristic function, the sum of independent random variables is the product of their CFs\n",
    "\n",
    "$$\\phi_{Z_n}(t) = \\phi_{\\sum_{i=1}^n \\frac{Y_i}{\\sqrt{n}}}(t) = \\prod_{i=1}^{n} \\phi_{Y_i}\\left(\\frac{t}{\\sqrt{n}}\\right) = \\left[ \\phi_{Y_1}\\left(\\frac{t}{\\sqrt{n}}\\right) \\right]^n$$\n",
    "\n",
    "After substituting in a Taylor series expansion we are left with\n",
    "\n",
    "$$\\phi_{Z_n}(t) = \\left[ 1 - \\frac{t^2}{2n} + o\\left(\\frac{1}{n}\\right) \\right]^n$$\n",
    "\n",
    "Take the limit as the sample size goes to infinity and we see convergence to the definition of Euler's number $e$\n",
    "\n",
    "$$\\lim_{n \\to \\infty} \\phi_{Z_n}(t) = \\lim_{n \\to \\infty} \\left[ 1 + \\frac{-t^2/2}{n} \\right]^n = e^{-t^2/2}$$\n",
    "\n",
    "Which is the characteristic function of a standard normal (Gaussian) distribution - fully specifying the random varibiable!\n",
    "\n",
    "**By Lévy's Continuity Theorem** \n",
    "\n",
    "Convergence of a characteristic function at $t = 0$ implies distribution convergence\n",
    "\n",
    "Therefore, the standardized sample mean converges to a normal (Gaussian) distribution - regardless of the population distribution!\n",
    "\n",
    "$$Z_n \\xrightarrow{d} N(0, 1) \\quad \\text{as } n \\to \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44625520",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fa70a",
   "metadata": {},
   "source": [
    "##### Example: Empirical Poisson Means are Normal \n",
    "\n",
    "$$x_i \\sim X \\sim Pois(\\lambda) \\quad\\quad \\frac{\\frac{1}{n}\\sum_{i = 1}^n x_i - \\lambda}{\\sqrt{\\frac{\\lambda}{n}}} \\sim N(0, 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f370a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "lmbda = 5\n",
    "n_samples_per_iter = 1000\n",
    "N_ITER = 500\n",
    "poisson_support = np.arange(0, 20)\n",
    "\n",
    "# --- True Poisson PMF ---\n",
    "pmf_poisson = stats.poisson.pmf(poisson_support, lmbda)\n",
    "\n",
    "# --- Generate empirical PMFs and sample means ---\n",
    "empirical_pmfs = []\n",
    "means = []\n",
    "for _ in range(N_ITER):\n",
    "    samples = np.random.poisson(lmbda, n_samples_per_iter)\n",
    "    counts, _ = np.histogram(samples, bins=np.arange(-0.5, max(poisson_support)+1.5), density=True)\n",
    "    empirical_pmfs.append(counts)\n",
    "    means.append(samples.mean())\n",
    "\n",
    "# --- Function to draw the figure for a given iteration ---\n",
    "def make_sampling_hist_fig(iteration):\n",
    "    emp_pmf = empirical_pmfs[iteration]\n",
    "    means_so_far = np.array(means[:iteration+1])\n",
    "\n",
    "    # Normalize the sample means (to show CLT convergence)\n",
    "    normalized_means = (means_so_far - lmbda) / np.sqrt(lmbda / n_samples_per_iter)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "                        column_widths=[0.5, 0.5],\n",
    "                        subplot_titles=(\"Empirical Mass Function\", \"Normalized Sample Means (Z)\"))\n",
    "\n",
    "    # LEFT PANEL: Empirical vs true PMF\n",
    "    fig.add_trace(go.Bar(x=poisson_support, y=emp_pmf,\n",
    "                         marker=dict(color='#00ffff', opacity=0.8),\n",
    "                         showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=poisson_support, y=pmf_poisson,\n",
    "                             mode='lines', line=dict(color='#d400ff', width=3, dash='dash'),\n",
    "                             showlegend=False), row=1, col=1)\n",
    "\n",
    "    # RIGHT PANEL: Histogram of normalized sample means\n",
    "    n_bins = 80\n",
    "    hist_y, hist_x = np.histogram(normalized_means, bins=n_bins, density=True)\n",
    "    bin_centers = (hist_x[:-1] + hist_x[1:]) / 2\n",
    "    fig.add_trace(go.Bar(x=bin_centers, y=hist_y,\n",
    "                         marker=dict(color='#7fcfff', opacity=0.8),\n",
    "                         showlegend=False), row=1, col=2)\n",
    "\n",
    "    # --- Theoretical Standard Normal Overlay ---\n",
    "    xx = np.linspace(-4, 4, 300)\n",
    "    normal_pdf = stats.norm.pdf(xx)\n",
    "    fig.add_trace(go.Scatter(x=xx, y=normal_pdf,\n",
    "                             mode='lines', line=dict(color='red', width=3, dash='dash'),\n",
    "                             showlegend=False), row=1, col=2)\n",
    "\n",
    "    # --- Axis scaling ---\n",
    "    fig.update_xaxes(title_text=\"k\", range=[-0.5, 12.5], row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"P(X=k)\", range=[0, max(pmf_poisson)*1.2], row=1, col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Z = (mean - λ) / sqrt(λ/n)\", range=[-4, 4], row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Density\", range=[0, 0.45], row=1, col=2)\n",
    "\n",
    "    # --- Styling ---\n",
    "    fig.update_layout(\n",
    "        height=420, width=900,\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        title_text=f\"Iteration {iteration+1}: Normalized Sample Mean Convergence to N(0,1)\",\n",
    "        title_x=0.5,\n",
    "        margin=dict(l=30, r=30, b=40, t=60)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "hist_frames = []\n",
    "for i in range(N_ITER):\n",
    "    f = make_sampling_hist_fig(i)\n",
    "    hist_frames.append(go.Frame(data=f.data,\n",
    "                                name=str(i),\n",
    "                                layout=go.Layout(\n",
    "                                    title_text=f\"Iteration {i+1}: Normalized Sample Mean Convergence to N(0,1)\"\n",
    "                                )))\n",
    "\n",
    "# --- Initial Figure ---\n",
    "hist_fig = make_sampling_hist_fig(0)\n",
    "hist_fig.frames = hist_frames\n",
    "\n",
    "# --- Controls ---\n",
    "hist_fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.12,\n",
    "        'xanchor': 'center',\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 30, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 60, 'easing': 'cubic-in-out'}\n",
    "            }]\n",
    "        }]\n",
    "    }],\n",
    "    transition={'duration': 60, 'easing': 'cubic-in-out'}\n",
    ")\n",
    "\n",
    "hist_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520bd2ad",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef4e9f",
   "metadata": {},
   "source": [
    "##### More Samples $\\rightarrow$ More Confidence\n",
    "\n",
    "The *variance of the sample mean* goes to zero as $n \\rightarrow \\infty$\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}\\left(\\bar{X}_n\\right) = \\frac{\\sigma^2}{n}\n",
    "$$\n",
    "\n",
    "This ensures convergence to the sample mean as observed in the Law of Large Numbers (LLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7395b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "mu = 5\n",
    "sigma = 2\n",
    "sample_sizes = [10, 30, 100, 250, 500]\n",
    "x = np.linspace(-5, 15, 400)\n",
    "\n",
    "# --- Function to get sampling distribution PDF ---\n",
    "def pdf_for_n(n):\n",
    "    std_err = sigma / np.sqrt(n)\n",
    "    return stats.norm.pdf(x, mu, std_err)\n",
    "\n",
    "# --- Color palette for each frame ---\n",
    "colors = ['#00FFFF', '#7FFF00', '#FFD700', '#FF7F50', '#FF1493']\n",
    "\n",
    "# --- Initial figure (first n) ---\n",
    "y0 = pdf_for_n(sample_sizes[0])\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=y0,\n",
    "    mode='lines',\n",
    "    line=dict(color=colors[0], width=4),\n",
    "    fill='tozeroy'\n",
    "))\n",
    "\n",
    "# --- Animation frames ---\n",
    "frames = []\n",
    "for n, c in zip(sample_sizes, colors):\n",
    "    y = pdf_for_n(n)\n",
    "    frames.append(go.Frame(\n",
    "        data=[go.Scatter(x=x, y=y,\n",
    "                         mode='lines',\n",
    "                         line=dict(color=c, width=4),\n",
    "                         fill='tozeroy')],\n",
    "        name=str(n),\n",
    "        layout=go.Layout(\n",
    "            title_text=f\"Sampling Distribution Tightening with Increasing n (n = {n})\"\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# --- Mean reference line (μ = 5) ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[mu, mu],\n",
    "    y=[0, 8],\n",
    "    mode='lines',\n",
    "    line=dict(color='red', width=3, dash='dash')\n",
    "))\n",
    "\n",
    "# --- Layout and styling ---\n",
    "fig.frames = frames\n",
    "fig.update_layout(\n",
    "    title=f\"Sampling Distribution Tightening Around μ = {mu}\",\n",
    "    xaxis_title=\"Sample Mean\",\n",
    "    yaxis_title=\"Density\",\n",
    "    xaxis_range=[3, 7],\n",
    "    yaxis_range=[0, 5],\n",
    "    showlegend=False,\n",
    "    font=dict(size=16, color='white'),\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    width=900, height=450,\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.2,  # lowered play button\n",
    "        'xanchor': 'center',\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 1000, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 700, 'easing': 'cubic-in-out'}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e893dc93",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f3476",
   "metadata": {},
   "source": [
    "#### Statistics $\\rightarrow$ Probabilities\n",
    "\n",
    "Remember, we don't know the *population distribution* that is generating the uncertain event we are modeling\n",
    "\n",
    "However, because we know that the sample mean converges to normality we can **generate probabilities** to assess the likelihood of different population data generating distributions!\n",
    "\n",
    "**Theoretical Calibration Procedure (Moment Matching)**\n",
    "\n",
    "1.) Observe a mean return\n",
    "\n",
    "2.) Parameterize (calibrate) a normal distribution by observed mean and variance\n",
    "\n",
    "3.) Find the probability of different states of the world!\n",
    "\n",
    "**Remark: Before you take to the comments my keyboard warrior friend, we are in the lab - I understand the notion of a leptokurtic return distribution, patience, we will get there**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431690fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import t, norm\n",
    "\n",
    "# --- Simulate Non-Normal Stock Returns (fat-tailed) ---\n",
    "np.random.seed(0)\n",
    "df = 3  # degrees of freedom for t-dist\n",
    "true_mu, true_sigma = 0.001, 0.02\n",
    "returns = true_mu + true_sigma * t.rvs(df, size=5000)\n",
    "\n",
    "# --- Fit a Normal Distribution to Sample ---\n",
    "mu_hat = np.mean(returns)\n",
    "sigma_hat = np.std(returns, ddof=1)\n",
    "\n",
    "# --- X range for plotting PDFs ---\n",
    "x = np.linspace(returns.min(), returns.max(), 600)\n",
    "\n",
    "# --- Fixed means to slide over (hypothetical distributions) ---\n",
    "slider_means = np.array([-0.012, -0.009, -0.003, 0.0, 0.003, 0.009, 0.012])\n",
    "\n",
    "# --- Initial position ---\n",
    "mu_initial = 0.0\n",
    "\n",
    "# --- Calculate the likelihood of observing sample mean if that distribution were true ---\n",
    "def likelihood_mu(mu, sample_mean, sigma, n):\n",
    "    # Normal PDF for MLE mean under dist with mean mu\n",
    "    # The likelihood of observing sample_mean as the sample mean from N(mu, sigma/sqrt(n))\n",
    "    # For the demonstration, treat sigma known and n large (use sample size)\n",
    "    return norm.pdf(sample_mean, loc=mu, scale=sigma/np.sqrt(n))\n",
    "\n",
    "n = len(returns)\n",
    "sample_mean = mu_hat\n",
    "likelihoods = [likelihood_mu(mu, sample_mean, sigma_hat, n) for mu in slider_means]\n",
    "\n",
    "# --- PDF for initial distribution ---\n",
    "pdf_initial = norm.pdf(x, mu_initial, sigma_hat)\n",
    "\n",
    "# --- Figure Setup ---\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\n",
    "        \"Sample of Stock Returns (Fat-Tailed)\",\n",
    "        f\"Hypothetical Normal Distributions\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- LEFT: Histogram of returns ---\n",
    "hist_y, hist_x = np.histogram(returns, bins=60, density=True)\n",
    "bin_centers = (hist_x[:-1] + hist_x[1:]) / 2\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers, y=hist_y,\n",
    "    marker=dict(color='#00ffff', opacity=0.6),\n",
    "    showlegend=False\n",
    "), row=1, col=1)\n",
    "\n",
    "# --- Mean line on left chart ---\n",
    "fig.add_shape(\n",
    "    type='line', x0=mu_hat, x1=mu_hat, y0=0, y1=max(hist_y)*1.1,\n",
    "    line=dict(color='red', width=3, dash='dot'),\n",
    "    xref='x1', yref='y1'\n",
    ")\n",
    "\n",
    "# --- RIGHT: Initial hypothetical normal PDF ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=pdf_initial, mode='lines',\n",
    "    line=dict(color='#B026FF', width=3),\n",
    "    hovertemplate='x=%{x:.4f}<br>PDF=%{y:.4f}<extra></extra>',\n",
    "    name=\"Hypothetical Distribution\",\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# --- Mark the observed sample mean ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[sample_mean], y=[norm.pdf(sample_mean, mu_initial, sigma_hat)],\n",
    "    mode='markers',\n",
    "    marker=dict(color='yellow', size=12, symbol='x'),\n",
    "    name=\"Observed sample mean\",\n",
    "    showlegend=True,\n",
    "    hovertemplate='Sample Mean: %{x:.4f}<extra></extra>'\n",
    "), row=1, col=2)\n",
    "\n",
    "# --- Prepare likelihood at initial mu ---\n",
    "likelihood_at_initial = likelihood_mu(mu_initial, sample_mean, sigma_hat, n)\n",
    "\n",
    "# --- Annotate likelihood ---\n",
    "INITIAL_SHAPE = [\n",
    "    dict(type='line', xref='x2', yref='y2',\n",
    "         x0=sample_mean, x1=sample_mean, y0=0, y1=norm.pdf(sample_mean, mu_initial, sigma_hat),\n",
    "         line=dict(color='yellow', width=3, dash='dot'))\n",
    "]\n",
    "INITIAL_ANNOTATION = [\n",
    "    dict(\n",
    "        x=sample_mean, y=norm.pdf(sample_mean, mu_initial, sigma_hat),\n",
    "        xref=\"x2\", yref=\"y2\",\n",
    "        text=f\"Likelihood: {likelihood_at_initial:.3e}\",\n",
    "        showarrow=True, arrowhead=2, ax=60, ay=-40,\n",
    "        font=dict(color='yellow', size=13),\n",
    "        bgcolor='rgba(0,0,0,0.7)'\n",
    "    )\n",
    "]\n",
    "\n",
    "# --- Slider steps: for each hypothetical mean, update right PDF and likelihood ---\n",
    "slider_steps = []\n",
    "for i, mu in enumerate(slider_means):\n",
    "    pdf = norm.pdf(x, mu, sigma_hat)\n",
    "    like = likelihood_mu(mu, sample_mean, sigma_hat, n)\n",
    "    step = dict(\n",
    "        method=\"update\",\n",
    "        label=f\"{mu:+.3f}\",\n",
    "        args=[\n",
    "            {\n",
    "                \"y\": [hist_y, pdf, [norm.pdf(sample_mean, mu, sigma_hat)]],\n",
    "                \"x\": [bin_centers, x, [sample_mean]]\n",
    "            },\n",
    "            {\n",
    "                \"title.text\": (\n",
    "                    f\"Hypothetical Normal (μ={mu:.4f}, σ={sigma_hat:.4f})<br>\"\n",
    "                    f\"Likelihood of observed sample mean: {like:.3e}\"\n",
    "                ),\n",
    "                \"shapes\": [\n",
    "                    dict(type='line', xref='x2', yref='y2',\n",
    "                         x0=sample_mean, x1=sample_mean, y0=0,\n",
    "                         y1=norm.pdf(sample_mean, mu, sigma_hat),\n",
    "                         line=dict(color='yellow', width=3, dash='dot'))\n",
    "                ],\n",
    "                \"annotations\": [\n",
    "                    dict(\n",
    "                        x=sample_mean, y=norm.pdf(sample_mean, mu, sigma_hat),\n",
    "                        xref=\"x2\", yref=\"y2\",\n",
    "                        text=f\"Likelihood: {like:.3e}\",\n",
    "                        showarrow=True, arrowhead=2, ax=60, ay=-40,\n",
    "                        font=dict(color='yellow', size=13),\n",
    "                        bgcolor='rgba(0,0,0,0.7)'\n",
    "                    )\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        execute=True\n",
    "    )\n",
    "    slider_steps.append(step)\n",
    "\n",
    "# --- Layout ---\n",
    "fig.update_layout(\n",
    "    height=550, width=1000,\n",
    "    title={'text': f\"Hypothetical Normal (μ={mu_initial:+.3f}, σ={sigma_hat:.4f})<br>\"\n",
    "                   f\"Likelihood of observed sample mean: {likelihood_at_initial:.3e}\",\n",
    "           'y': 0.96, 'x': 0.5, 'xanchor': 'center'},\n",
    "    font=dict(color='white'),\n",
    "    showlegend=False,\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    shapes=INITIAL_SHAPE,\n",
    "    annotations=INITIAL_ANNOTATION,\n",
    "    sliders=[dict(\n",
    "        steps=slider_steps,\n",
    "        active=np.where(np.isclose(slider_means, mu_initial))[0][0],\n",
    "        pad={\"t\": 50, \"b\": 0},\n",
    "        yanchor='top', y=-0.10,\n",
    "        x=0.65, len=0.30,\n",
    "        currentvalue={\"prefix\": \"Hypothetical μ = \", \"font\": {\"color\": \"white\", \"size\": 16}}\n",
    "    )]\n",
    ")\n",
    "\n",
    "# --- Axis formatting ---\n",
    "fig.update_xaxes(\n",
    "    title_text='Return',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text='Density',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title_text='Return',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    range=[-0.08, 0.08],\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text='Density',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    range=[0, 13],\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8843ec1",
   "metadata": {},
   "source": [
    "Thanks to the Central Limit Theorem (CLT) we don't have to make an assumption about the population distribution of sample mean returns and can find *actual* probabilities of different states of the world for our sample mean return!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c138f5",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac56dc",
   "metadata": {},
   "source": [
    "##### Applications of the Central Limit Theorem (CLT)\n",
    "\n",
    "- Parameter Calibration\n",
    "\n",
    "- Generating Probabilities\n",
    "\n",
    "- Confidence Intervals\n",
    "\n",
    "- Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5475efc",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aee092",
   "metadata": {},
   "source": [
    "##### Application to Stock Returns\n",
    "\n",
    "We can observe the mean return of NVDA over disjoint 90-day blocks\n",
    "\n",
    "$$\\implies \\bar{X}_{90} \\sim N(\\mu, \\sigma^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a7bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import norm\n",
    "\n",
    "# --- Load NVDA close prices and calculate daily returns ---\n",
    "df = pd.read_csv(\"NVDA_returns.csv\")\n",
    "df = df.iloc[::-1]  # chronological (oldest to newest)\n",
    "returns = df['Close'].pct_change().dropna().values\n",
    "\n",
    "# --- Use disjoint time blocks of 90 days ---\n",
    "block_size = 90\n",
    "num_blocks = len(returns) // block_size\n",
    "block_means = [np.mean(returns[i*block_size:(i+1)*block_size]) for i in range(num_blocks)]\n",
    "block_means = np.array(block_means)\n",
    "n = block_size  # Each block is a sample of size block_size\n",
    "\n",
    "# --- Fit normal distribution to the mean of each block (CLT on block means) ---\n",
    "sample_mean = block_means.mean()\n",
    "sample_std = block_means.std(ddof=1)\n",
    "se_mean = sample_std / np.sqrt(num_blocks)\n",
    "\n",
    "# --- Probability that block mean return is less than zero (CLT) ---\n",
    "prob_less_than_zero = norm.cdf(0, loc=sample_mean, scale=se_mean)\n",
    "\n",
    "# --- Extract year range for plot subtitle ---\n",
    "df_dates = pd.to_datetime(df['Date'])\n",
    "start_year = df_dates.min().year\n",
    "end_year = df_dates.max().year\n",
    "\n",
    "# --- Histogram of ALL DAILY RETURNS (LEFT) ---\n",
    "hist_y, hist_x = np.histogram(returns, bins=30, density=True)\n",
    "bin_centers = (hist_x[:-1] + hist_x[1:]) / 2\n",
    "\n",
    "# --- Normal PDF for mean sampling distribution (block means, RIGHT) ---\n",
    "x_mu = np.linspace(sample_mean - 5*se_mean, sample_mean + 5*se_mean, 400)\n",
    "pdf_mu = norm.pdf(x_mu, loc=sample_mean, scale=se_mean)\n",
    "\n",
    "# --- Calculate Y axis ranges ---\n",
    "ylim_hist = max(hist_y) * 1.2\n",
    "ylim_pdf  = max(pdf_mu) * 1.2\n",
    "\n",
    "# --- Subplot setup: 1 row x 2 columns ---\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\n",
    "        f\"NVDA Daily Return Histogram<br>({start_year}–{end_year})\",\n",
    "        f\"Block-mean (n={block_size}) Normal Distribution ({num_blocks} blocks)\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- LEFT: Actual returns histogram ---\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers, y=hist_y,\n",
    "    marker=dict(color=\"#00FFFF\", opacity=0.85),\n",
    "    name='Returns Histogram',\n",
    "    showlegend=False,\n",
    "), row=1, col=1)\n",
    "\n",
    "# --- Mean line of all daily returns ---\n",
    "daily_mean = np.mean(returns)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[daily_mean, daily_mean],\n",
    "    y=[0, ylim_hist],\n",
    "    mode='lines',\n",
    "    line=dict(color='red', width=3, dash='dash'),\n",
    "    showlegend=False,\n",
    "), row=1, col=1)\n",
    "\n",
    "# --- RIGHT: Only normal fit (NO HISTOGRAM!), just the normal distribution ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_mu, y=pdf_mu,\n",
    "    mode='lines',\n",
    "    line=dict(color='#B026FF', width=3),\n",
    "    name='Normal Fit for Block Means',\n",
    "    hovertemplate=\"Mean={x:.4f}<br>PDF={y:.4f}<extra></extra>\",\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# --- Mean line on the normal fit ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[sample_mean, sample_mean],\n",
    "    y=[0, ylim_pdf],\n",
    "    mode='lines',\n",
    "    line=dict(color='red', width=3, dash='dash'),\n",
    "    name='Sample Mean',\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# --- Shade area P(mean < 0) on the sampling distribution (normal fit) ---\n",
    "x_fill = x_mu[x_mu <= 0]\n",
    "pdf_fill = norm.pdf(x_fill, loc=sample_mean, scale=se_mean)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([x_fill, x_fill[::-1]]),\n",
    "    y=np.concatenate([pdf_fill, np.zeros_like(pdf_fill)]),\n",
    "    fill='toself', mode='none',\n",
    "    fillcolor='rgba(0,255,255,0.35)',\n",
    "    showlegend=False\n",
    "), row=1, col=2)\n",
    "\n",
    "# --- Styling/annotations to match CLT theme ---\n",
    "annot_mean = dict(\n",
    "    x=daily_mean,\n",
    "    y=ylim_hist * 0.74,\n",
    "    xref='x1', yref='y1',\n",
    "    text=f\"Daily Mean: {daily_mean*100:.3f}%\",\n",
    "    showarrow=False,\n",
    "    font=dict(color='red', size=16),\n",
    "    bgcolor='rgba(255,255,255,0.12)'\n",
    ")\n",
    "annot_mu_norm = dict(\n",
    "    x=sample_mean,\n",
    "    y=ylim_pdf * 0.89,\n",
    "    xref='x2', yref='y2',\n",
    "    text=f\"<b>Block Means: μ={sample_mean*100:.3f}%<br>σₘ={se_mean*100:.3f}%</b><br>P(μ < 0) = {prob_less_than_zero:.4f}\",\n",
    "    showarrow=False,\n",
    "    font=dict(color='#B026FF', size=15),\n",
    "    bgcolor='rgba(255,255,255,0.08)'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500, width=900,\n",
    "    plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(size=16, color='white'),\n",
    "    showlegend=False,  # **REMOVE LEGEND**\n",
    "    title=dict(\n",
    "        text=f\"NVDA Stock Returns and CLT (90-Day Block Means)\",\n",
    "        font=dict(size=22, color='white'),\n",
    "        y=0.97, x=0.5, xanchor='center'\n",
    "    ),\n",
    "    annotations=[annot_mean, annot_mu_norm],\n",
    "    margin=dict(l=40, r=30, t=70, b=40),\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    title_text='Return',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text='Density',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    range=[0, ylim_hist],\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    title_text=f'Block Mean (n={block_size})',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title_text='Probability Density',\n",
    "    showgrid=True,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    range=[0, ylim_pdf],\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe37f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probability that a disjoint 90-day block mean is negative\n",
    "block_mean_neg_prob = prob_less_than_zero\n",
    "\n",
    "# Avoid division by zero\n",
    "if block_mean_neg_prob == 0:\n",
    "    expected_blocks = np.inf\n",
    "    expected_years = np.inf\n",
    "else:\n",
    "    expected_blocks = 1 / block_mean_neg_prob\n",
    "    # There are trading_days_per_year / 90 non-overlapping 90-day blocks per year\n",
    "    trading_days_per_year = 252\n",
    "    blocks_per_year = trading_days_per_year / 90\n",
    "    expected_years = expected_blocks / blocks_per_year\n",
    "\n",
    "print(f\"Expected years until a negative mean return in a disjoint 90-day block: {expected_years:.2f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3ad23",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count observed negative 90-day block means\n",
    "neg_mean_indices = np.where(block_means < 0)[0]\n",
    "num_neg_blocks = len(neg_mean_indices)\n",
    "\n",
    "# Build a year vs. negative-mean-block indicator time series\n",
    "# For plotting, assign the block mean to the last day of its block\n",
    "block_end_indices = [(i+1)*block_size - 1 for i in range(num_blocks)]\n",
    "block_end_dates = df_dates.iloc[block_end_indices].reset_index(drop=True)\n",
    "\n",
    "# Boolean time series for negative block mean\n",
    "neg_blocks_ts = np.zeros(num_blocks)\n",
    "neg_blocks_ts[neg_mean_indices] = 1\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "neg_blocks_plot = go.Figure()\n",
    "\n",
    "# Main time series: \n",
    "# - Positive-block means: green dots (opacity 0.2)\n",
    "# - Negative-block means: red dots\n",
    "positive_mask = block_means >= 0\n",
    "negative_mask = block_means < 0\n",
    "\n",
    "# Plot positive (green, opacity=0.2) block means\n",
    "neg_blocks_plot.add_trace(go.Scatter(\n",
    "    x=block_end_dates[positive_mask],\n",
    "    y=block_means[positive_mask],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='#00FF00',\n",
    "        size=12,\n",
    "        line=dict(color='gray', width=1),\n",
    "        opacity=0.2\n",
    "    ),\n",
    "    name='Positive Block Means',\n",
    "    hovertemplate=\"Date=%{x}<br>Mean Return=%{y:.4%}<extra></extra>\",\n",
    "    showlegend=False,\n",
    "))\n",
    "\n",
    "# Plot negative (red) block means\n",
    "neg_blocks_plot.add_trace(go.Scatter(\n",
    "    x=block_end_dates[negative_mask],\n",
    "    y=block_means[negative_mask],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color='red',\n",
    "        size=12,\n",
    "        line=dict(color='gray', width=1),\n",
    "        opacity=1\n",
    "    ),\n",
    "    name='Negative Block Means',\n",
    "    hovertemplate=\"Date=%{x}<br>Mean Return=%{y:.4%}<extra></extra>\",\n",
    "    showlegend=False,\n",
    "))\n",
    "\n",
    "# Add red vertical lines at each negative block\n",
    "for idx in neg_mean_indices:\n",
    "    date = block_end_dates.iloc[idx]\n",
    "    neg_blocks_plot.add_shape(\n",
    "        dict(\n",
    "            type=\"line\",\n",
    "            x0=date, x1=date, \n",
    "            y0=min(block_means)-abs(min(block_means)*0.1), y1=max(block_means)+abs(max(block_means)*0.1),\n",
    "            line=dict(color=\"red\", width=2, dash=\"solid\"),\n",
    "            layer=\"below\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add a line at y=0\n",
    "neg_blocks_plot.add_trace(go.Scatter(\n",
    "    x=[block_end_dates.min(), block_end_dates.max()],\n",
    "    y=[0, 0],\n",
    "    mode='lines',\n",
    "    line=dict(color='white', width=2, dash='dash'),\n",
    "    showlegend=False,\n",
    "    hoverinfo='skip'\n",
    "))\n",
    "\n",
    "neg_blocks_plot.update_layout(\n",
    "    title=f\"NVDA: 90-Day Block Mean Returns<br><span style='font-size:17px'>Total negative means: {num_neg_blocks} of {num_blocks} ({100*num_neg_blocks/num_blocks:.1f}%)</span>\",\n",
    "    xaxis_title=\"Block End Date\",\n",
    "    yaxis_title=\"90-Day Block Mean Return\",\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color=\"white\", size=17),\n",
    "    height=430,\n",
    "    width=850,\n",
    "    margin=dict(l=40, r=30, t=80, b=40),\n",
    ")\n",
    "neg_blocks_plot.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.18)')\n",
    "neg_blocks_plot.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.18)')\n",
    "\n",
    "neg_blocks_plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ce67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Years required to observe the negative blocks we have: {expected_years*20:.2f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fde743",
   "metadata": {},
   "source": [
    "Something in our model appears to be incorrect, we've observed barely over two decades of returns and we are seeing far more negative returns than expected - why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91447e9",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0d039",
   "metadata": {},
   "source": [
    "##### Limitations and Considerations\n",
    "\n",
    "It is true that the population distribution of sample means is normal, but it changes over time\n",
    "\n",
    "This is why we are grossly underestimating the probability of losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09721b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set random seed and sample count\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Parameters for time-varying normal distributions (drifting mean)\n",
    "n_frames = 60\n",
    "means = np.concatenate([\n",
    "    np.linspace(0, 2, n_frames//3),  # Drift positive\n",
    "    np.linspace(2, -2, n_frames//3), # Drift negative \n",
    "    np.linspace(-2, 0, n_frames//3)  # Return to neutral\n",
    "])\n",
    "\n",
    "# Parameters for the fixed normal distribution (mean and variance in % units)\n",
    "fixed_mean = 0.2      \n",
    "fixed_var = 0.05        \n",
    "fixed_std = np.sqrt(fixed_var) # std dev\n",
    "\n",
    "# Plotting range and precompute fixed PDF\n",
    "x_range = np.linspace(-4, 4, 200)\n",
    "fixed_pdf = stats.norm.pdf(x_range, loc=fixed_mean, scale=fixed_std)\n",
    "\n",
    "frames = []\n",
    "all_samples = []\n",
    "\n",
    "for mean in means:\n",
    "    X = np.random.normal(mean, 1, n_samples)\n",
    "    kde_X = stats.gaussian_kde(X)\n",
    "    \n",
    "    # 10 new drifting samples (accumulate for histogram)\n",
    "    samples = np.random.normal(mean, 1, 10)\n",
    "    all_samples.extend(samples)\n",
    "\n",
    "    # Top subplot: drifting (magenta) and fixed (orange) normals\n",
    "    drifting_curve = go.Scatter(\n",
    "        x=x_range,\n",
    "        y=kde_X(x_range),\n",
    "        mode='lines',\n",
    "        line=dict(color='rgba(255, 0, 255, 1)', width=2),\n",
    "        name='Drifting Normal'\n",
    "    )\n",
    "    fixed_curve = go.Scatter(\n",
    "        x=x_range,\n",
    "        y=fixed_pdf,\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', width=2, dash='dash'),\n",
    "        name='Fixed Normal (μ=0.2%, σ²=0.05%)'\n",
    "    )\n",
    "    # Bottom: histogram of all accumulated drifting samples\n",
    "    histogram = go.Histogram(\n",
    "        x=all_samples,\n",
    "        nbinsx=20,\n",
    "        name='Sample Distribution',\n",
    "        marker_color='rgba(0, 255, 255, 0.6)'\n",
    "    )\n",
    "    frames.append(\n",
    "        go.Frame(\n",
    "            data=[drifting_curve, fixed_curve, histogram]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Build subplot figure\n",
    "fig = make_subplots(rows=2, cols=1, row_heights=[0.6, 0.4])\n",
    "\n",
    "# Add initial traces: drifting, fixed, histogram\n",
    "fig.add_trace(frames[0].data[0], row=1, col=1)  # Drifting\n",
    "fig.add_trace(frames[0].data[1], row=1, col=1)  # Fixed\n",
    "fig.add_trace(frames[0].data[2], row=2, col=1)  # Histogram\n",
    "\n",
    "# Animation setup\n",
    "fig.frames = frames\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 50, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=900,\n",
    "    showlegend=True,\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    title='Drifting Return Distribution with Accumulated Samples<br>and Fixed Normal Reference'\n",
    ")\n",
    "\n",
    "# Top subplot axes\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor='rgba(128,128,128,0.5)',\n",
    "    range=[-4, 4],\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor='rgba(128,128,128,0.5)',\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bottom subplot axes and limits\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor='rgba(128,128,128,0.5)',\n",
    "    range=[-4, 4],\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor='rgba(128,128,128,0.2)',\n",
    "    zeroline=True,\n",
    "    zerolinewidth=1,\n",
    "    zerolinecolor='rgba(128,128,128,0.5)',\n",
    "    range=[0, 100],\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01ef3b",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e8a5f",
   "metadata": {},
   "source": [
    "##### Central Limit Theorem (CLT) Provides a Point-in-Time Probability Snapshot\n",
    "\n",
    "**Trading Signal Example**\n",
    "\n",
    "In some cases the *assumption* that the sample reflects the data generating distribution is less violent than others\n",
    "\n",
    "For example, if I am trying to assess the sentiment of an equity before *9:20am* and I have a sample of $50$ unique documents, after calibrating a normal distribution I can assess the probability of drawing an *incorrect* signal (observed mean) given a threshold for inclusion in our portfolio.  \n",
    "\n",
    "If the probability is too low, I won't include the equity in that bucket and I won't trade it in either the L/S leg.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c988159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Recentered Normal Distribution at Threshold — Assessing Probability of Observed Mean\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Suppose we threshold accept for inclusion at a certain sample mean, e.g., 0.05\n",
    "threshold_mean = 0.05\n",
    "sample_size = 50\n",
    "# Observed mean sentiment from sample\n",
    "observed_mean = 0.15\n",
    "observed_std = 0.3\n",
    "\n",
    "# CLT std deviation\n",
    "clt_std = observed_std / np.sqrt(sample_size)\n",
    "\n",
    "# Center the normal under the null hypothesis (that true mean is right at the inclusion threshold)\n",
    "center = threshold_mean\n",
    "\n",
    "x = np.linspace(-0.1, 0.4, 300)\n",
    "pdf = norm.pdf(x, loc=center, scale=clt_std)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Main normal curve (centered at threshold for inclusion)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=pdf,\n",
    "    mode=\"lines\",\n",
    "    line=dict(color='orange', width=3, dash=\"dash\"),\n",
    "    name=\"Null Sampling Distribution<br>(mean = threshold)\"\n",
    "))\n",
    "\n",
    "# Vertical line for actually observed sample mean\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[observed_mean, observed_mean],\n",
    "    y=[0, norm.pdf(observed_mean, loc=center, scale=clt_std)],\n",
    "    mode=\"lines\",\n",
    "    line=dict(color=\"magenta\", width=3),\n",
    "    name=\"Observed Mean\"\n",
    "))\n",
    "\n",
    "# Compute (one-sided) probability (p-value) of seeing a sample mean as large or larger than observed_mean, if true mean is threshold\n",
    "p_value = 1 - norm.cdf(observed_mean, loc=center, scale=clt_std)\n",
    "\n",
    "# Fill the right-side tail, i.e., region with mean ≥ observed_mean\n",
    "fill_x = np.linspace(observed_mean, x[-1], 100)\n",
    "fill_y = norm.pdf(fill_x, loc=center, scale=clt_std)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([fill_x, fill_x[::-1]]),\n",
    "    y=np.concatenate([fill_y, np.zeros_like(fill_y)]),\n",
    "    fill=\"toself\",\n",
    "    fillcolor='rgba(0,255,255,0.3)',\n",
    "    line=dict(color=\"rgba(0,0,0,0)\"),\n",
    "    name=f\"P(≥ observed mean) = {p_value:.4f}\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"CLT Sampling Distribution under Threshold: P(Observed Mean or Higher)\",\n",
    "    xaxis_title=\"Sentiment (Sample Mean)\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    height=420,\n",
    "    width=850,\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    legend=dict(bgcolor=\"rgba(0,0,0,0)\", bordercolor=\"rgba(0,0,0,0)\")\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    showgrid=True,\n",
    "    gridcolor=\"rgba(128,128,128,0.20)\",\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showgrid=True,\n",
    "    gridcolor=\"rgba(128,128,128,0.20)\",\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# -- Interpretation text for this plot (to be displayed, not code): --\n",
    "# \"The orange dashed curve is the CLT sampling distribution for mean sentiment if the 'true' mean were exactly at our inclusion threshold.\n",
    "# The magenta line is the mean we actually observed. The shaded right area is the probability of observing a mean this favorable (or greater) \n",
    "# just by chance — if this probability is very low (e.g., less than 5%), we are confident the sample is unusually favorable and may include the equity;\n",
    "# otherwise, if it's too high, our signal could easily have arisen by luck, so we might skip trading it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a29a0f",
   "metadata": {},
   "source": [
    "In this case, the distribution does change over time (we know this)\n",
    "\n",
    "But we need to assess the likelihood of this state of the world *now* to make a trading decision\n",
    "\n",
    "Even though the distribution changes, it may be relatively stable *now* - quite a useful concept!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d011a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a31bc",
   "metadata": {},
   "source": [
    "#### 4.)  Closing Thoughts and Future Topics\n",
    "\n",
    "**TL;DW Executive Summary**\n",
    "- Random variables define a set of outcomes with accompanying probabilities or likelihoods (discrete / continuous)\n",
    "- Anytime we draw a random variable we are dealing with an empirical distribution that can generate statistics\n",
    "- If draws are from the same population distribution (i.e. it is time invariant) empirical statistics and distributions converge by the LLN, this is not the case in practice as we are battling time variance in distributions and subsequent statistics. . .\n",
    "- Given draws from a population distribution are random variables, statistics (being a function of the empirical distribution) are also random variables, what distribution do they follow?\n",
    "- The distribution of sample means follows a normal (Gaussian) distribution regardless of the population or data generating distribution, this is quite literally our bridge between theory and practice, statistics and probability\n",
    "- If the population or data generating distribution is fixed the distribution of sample means will converge to a normal distribution as the sample size becomes arbitrarily large and probabilities will be precise in the frequentist sense\n",
    "- In reality, population or data generating distributions are **NOT** fixed and are time variant leading us to generate incorrect probabilities and draw statistically incorrect conclusions\n",
    "- Though distributions in reality change over time, the CLT can offer a **snapshot** which is useful locally for generating probabilities as we saw in the trading signal example where the sentiment distribution producing a trading decision is likely to be more stable in that short region of time (minutes) required to generate a decision than it is to be stable over a series of days (which doesn't matter nearly as much as we will continue to recalibrate our model to new data)\n",
    "\n",
    "**Future Topics**\n",
    "\n",
    "Technical Videos and Other Discussions\n",
    "\n",
    "- Advanced Markov Chains (Absorbing States, Communication Classes, Ergodicity and Stationary Distributions, . . .)\n",
    "- Non-Markovian Models (fractional Brownian motion, Volterra Process)\n",
    "- Deriving the Black-Scholes Equation: PDE, Analytical/Numerical Solutions\n",
    "- Kalman Filters and Non-Stationary (A Big Problem in Quant Modeling)\n",
    "- Risk-Neutral Measures (Complete vs Incomplete Markets)\n",
    "- Reinforcement Learning for Delta Hedging\n",
    "- Approximating Pricing Functionals using Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "[Ideas for Interactive Brokers Apps and Tutorials](https://www.interactivebrokers.com/mkt/?src=quantguildY&url=%2Fen%2Fwhyib%2Foverview.php)\n",
    "\n",
    "- Live Neural Network Stochastic Volatility Model Calibration\n",
    "- Live Kalman Filter Model with Regime Dynamics (MCs/HMMs) \n",
    "- Automated Delta-Neutral Trading System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c383c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b85867",
   "metadata": {},
   "source": [
    "####  $\\text{Copyright © 2025 Quant Guild} \\quad \\quad \\quad \\quad \\text{Author: Shreejit Verma (GitHub: shreejitverma)}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
